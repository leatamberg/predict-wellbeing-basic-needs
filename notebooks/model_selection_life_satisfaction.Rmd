---
title: "Model selection for cross-sectional life satisfaction using cross-validation"
html_notebook: default
---
packages
```{r, warning = FALSE, message=FALSE}
library(readxl)
library(writexl)
library(dplyr)
library(tidyverse)
library(caret)
library(countrycode)
library(readr)
library(stats)
library(stargazer)
library(latex2exp)
library(janitor)
library(viridis)
library(factoextra)
library(modelr)
library(glmnet)
library(tidymodels)
library(mgcv)
library(sfsmisc)
library(earth)
library(pdp)
library(rpart.plot)
library(ranger)
library(rlang)
library(leaps)
library(rPref)
library(selectiveInference)
library(parameters)
library(ggfortify)
library(gratia)

tidymodels_prefer()

# for Latex fonts: 
library(extrafont)
```

helper functions
```{r}
source("../utils/step_select_p_value.R")
source("../utils/step_select_p_value_iterative.R")
source("../utils/step_select_lasso.R")
source("../utils/step_select_leaps.R")

source("../utils/utils_validation.R")
```



# Preparation
## Data
```{r}
data_2015 <- 
  read_xlsx("../data/dataset_need_satisfiers_2015.xlsx") 

country_neighbors <- 
  read_xlsx("../data/dataset_country_neighbors.xlsx")
```


## CV folds

generate different kinds of fold splits for cross-validation
```{r}
set.seed(42)

singls_region_folds <- group_vfold_cv(data_2015, group = region)

k_folds <- vfold_cv(data_2015, v = 5, repeats = 5)

balanced_region_folds <- group_vfold_cv(data_2015, group = region, v= 5, repeats = 5, balance = "observations")

balanced_region_folds_1_repeat <- group_vfold_cv(data_2015, group = region, v= 5, repeats = 1, balance = "observations")

# define control parameters for cross-validation that allow to extract different information from each fold's model
cv_control = control_resamples(extract = get_model_stats, save_pred = TRUE)

```

check how even the balanced region folds are regarding number of samples per fold

```{r}
balanced_region_folds_1_repeat %>% 
  tidy() %>% 
  filter(Data == "Assessment") %>% 
  group_by(Fold) %>% 
  summarise(n_samples = n())
```


## Base formulas

define ols model
```{r}
lin_spec <- 
    linear_reg() %>% 
    set_engine("lm")
```

formula with all predictors
```{r}
formula_all <- 
  life_satisfaction ~ 
  undernourishment +
         obesity +

        
         drinking_water_basic +
         
         electricity +
         sanitation_basic +

         clean_cooking_gbd +
         air_pollution_particles +
         air_pollution_ozone +
         
         uhc_who +
         dtp3 +


         unmet_contraception +
         
         social_support +
         
         stability +
         
         cbn_poverty +
         unemployment_ilo +
         
         lower_secondary_school +

         voice +

         freedom +



         alcohol +

         HIV_unaids_untreated +

         gdp
  


formula_all_log <- 
  life_satisfaction ~ 
  undernourishment +
         obesity +

        
         drinking_water_basic +
         
         electricity +
         sanitation_basic +

         clean_cooking_gbd +
         air_pollution_particles +
         air_pollution_ozone +
         
         uhc_who +
         dtp3 +


         unmet_contraception +
         
         social_support +
         
         stability +
         
         cbn_poverty +
         unemployment_ilo +
         
         lower_secondary_school +

         voice +

         freedom +



         alcohol +

         HIV_unaids_untreated +

         log(gdp)

```

# Group 1: Regularisation
## Scan huge workflowset

```{r}
scan_recipe_set <- 
   list("log_lasso_sel" = recipe(formula = formula_all,
                     data = data_2015
                     ) %>%
              step_log(gdp) %>%
              step_select_lasso(all_predictors(), outcome = "life_satisfaction",
                                               penalty = tune("lasso_sel")),
      "lasso_sel" = recipe(formula = formula_all,
                     data = data_2015
                     ) %>%
              step_select_lasso(all_predictors(), outcome = "life_satisfaction",
                                               penalty = tune("lasso_sel")),

      "log_all" = recipe(formula = formula_all,
                       data = data_2015
                       ) %>%
                step_log(gdp),
      "all" = recipe(formula = formula_all,
                     data = data_2015
                     ),
      "log_sig_iterative" = recipe(formula = formula_all,
                     data = data_2015
                     ) %>%
              step_log(gdp) %>% 
              step_select_p_value_iterative(all_predictors(), outcome = "life_satisfaction", 
                                               threshold = tune(), initial_threshold = 0.6),
      "sig_iterative" = recipe(formula = formula_all,
                     data = data_2015
                     ) %>%
              step_select_p_value_iterative(all_predictors(), outcome = "life_satisfaction", 
                                               threshold = tune(), initial_threshold = 0.6),
      "log_exhaustive_Cp" = recipe(formula = formula_all,
                     data = data_2015
                     ) %>%
              step_log(gdp) %>% 
              step_select_leaps(all_predictors(), outcome = "life_satisfaction", 
                                               eval_criterion = "Cp"),
      "log_exhaustive_BIC" = recipe(formula = formula_all,
                     data = data_2015
                     ) %>%
              step_log(gdp) %>% 
              step_select_leaps(all_predictors(), outcome = "life_satisfaction", 
                                               eval_criterion = "BIC"),
      "exhaustive_Cp" = recipe(formula = formula_all,
                     data = data_2015
                     ) %>%
              step_select_leaps(all_predictors(), outcome = "life_satisfaction", 
                                               eval_criterion = "Cp"),
      "exhaustive_BIC" = recipe(formula = formula_all,
                     data = data_2015
                     ) %>%
              step_select_leaps(all_predictors(), outcome = "life_satisfaction", 
                                               eval_criterion = "BIC"),
      "log_pca" = recipe(formula = formula_all,
                 data = data_2015
                 ) %>%
          step_log(gdp) %>% 
          step_pca(all_numeric_predictors(), threshold = tune(), options = list(center = TRUE, scale. =TRUE)),
      "pca" = recipe(formula = formula_all,
                     data = data_2015
                     ) %>% 
            step_pca(all_numeric_predictors(), threshold = tune(), options = list(center = TRUE, scale. =TRUE))
    
  )

scan_models <- list(ols = lin_spec,  
                    lasso = linear_reg(
                              penalty = tune("lasso_model"), 
                              mixture = 1, 
                              engine = "glmnet"),
                    ridge = linear_reg(
                              penalty = tune("ridge"), 
                              mixture = 0) %>% set_engine("glmnet", path_values = c(0, 10^seq(-10, 0, length.out = 11)))
)


scan_workflows <- 
  workflow_set(
    preproc = scan_recipe_set, 
    models = scan_models) 


```

```{r}
cv_results_ls_k_scan <- scan_workflows %>% workflow_map("tune_grid", resamples = k_folds, 
                                                        grid = 10,
                                                        verbose = TRUE)
```


```{r}
saveRDS(cv_results_ls_k_scan, file = "../results/cv_results_ls_k_scan.rds", ascii = FALSE, version = NULL,
        compress = TRUE, refhook = NULL)

```

```{r}
cv_results_ls_k_scan <- readRDS(file = "../results/cv_results_ls_k_scan.rds")

```





```{r}
rank_results(cv_results_ls_k_scan, rank_metric = "rmse") %>% 
  select(-c(.config, preprocessor, model)) %>% 
  filter(.metric=="rmse") %>% 
  group_by(wflow_id) %>% 
  summarize(best_rmse = min(mean)) %>% 
  arrange(best_rmse)
```


```{r}
detailed_results <- 
  cv_results_ls_k_scan %>% 
  extract_workflow_set_result("pca_lasso")

detailed_results %>% collect_metrics() %>% select(-c(.config)) %>% filter(.metric=="rmse") %>% arrange(mean)
```
```{r}
detailed_results %>% autoplot(metric = "rmse")
```



## Finetuning

#### log_all_ridge
```{r}
workflow_ridge <- workflow(preprocessor = recipe(formula = formula_all,
                                               data = data_2015
                                               ) %>%
                                          step_log(gdp),
                          spec = linear_reg(
                              penalty = tune("ridge"), 
                              mixture = 0) %>% set_engine("glmnet", path_values = c(0, 10^seq(-4, 1, length.out = 11)))
                            )
tune_ridge <- 
  workflow_ridge %>%
  tune_grid(resamples = k_folds, 
            grid = expand_grid(ridge = c(0,seq(0.05,0.3, by=0.025))),
            metrics = metric_set(yardstick::rmse))

```
```{r}
tune_ridge %>% collect_metrics() %>% select(-c(.config)) %>% filter(.metric=="rmse") %>% arrange(mean)
```
```{r}
tune_ridge %>% 
  autoplot()
```
```{r}
tune_ridge %>% select_by_one_std_err(metric = "rmse", desc(ridge))
```



### log_all_lasso
```{r}
tune_log_all_lasso <- 
  cv_results_ls_k_scan %>% 
  extract_workflow("log_all_lasso") %>% 
  tune_grid(resamples = k_folds, 
            grid = expand_grid(lasso_model = c(0.006,seq(0.034,0.036, by = 0.0005))),
              #grid_regular(list(lasso_model= penalty(c(-4,-2))), levels = 10),
            metrics = metric_set(yardstick::rmse))
```

```{r}
tune_log_all_lasso %>% collect_metrics() %>% select(-c(.config)) %>% filter(.metric=="rmse") %>% filter(n==25) %>% arrange(mean)
```

```{r}
tune_log_all_lasso %>% autoplot()
```
```{r}
tune_log_all_lasso %>% select_by_one_std_err(metric = "rmse", desc(lasso_model))
```
```{r}
cv_results_ls_k_scan %>% 
  extract_workflow("log_all_lasso") %>% 
  finalize_workflow(tune_log_all_lasso %>% 
                      select_by_one_std_err(metric = "rmse", desc(lasso_model))) %>%
  fit(data_2015) %>% tidy() %>% filter(estimate!=0)
```

### log_sig_iterative_ols

```{r}
tune_log_sig_iterative_ols <- 
  cv_results_ls_k_scan %>% 
  extract_workflow("log_sig_iterative_ols") %>% 
  # update_recipe(recipe(formula = formula_all,
  #                    data = data_2015
  #                    ) %>%
  #             step_log(gdp) %>% 
  #             step_select_p_value_iterative(all_predictors(), outcome = "life_satisfaction", 
  #                                              threshold = tune(), initial_threshold = 0.9)) %>% 
  tune_grid(resamples = k_folds, 
            grid = expand_grid(threshold= c(0.6,seq(0.2,0.1, by = -0.03))),
            metrics = metric_set(yardstick::rmse))
```
```{r}
tune_log_sig_iterative_ols %>% collect_metrics() %>% select(-c(.config)) %>% filter(.metric=="rmse") %>% arrange(mean)
```
```{r}
tune_log_sig_iterative_ols %>% 
  collect_metrics() %>% 
  filter(.metric=="rmse") %>% 
  ggplot(aes(x=threshold, y=mean)) +
  geom_point() +
  geom_line()
```
```{r}
tune_log_sig_iterative_ols %>% select_by_one_std_err(metric = "rmse", threshold)
```

```{r}
cv_results_ls_k_scan %>% 
  extract_workflow("log_sig_iterative_ols") %>% 
  finalize_workflow(tune_log_sig_iterative_ols %>% 
                      select_by_one_std_err(metric = "rmse", threshold)) %>%
  fit(data_2015) %>% tidy()
```

# Group 2: Nonlinearities and interactions

## Random forest

```{r}
workflow_random_forest <- workflow(preprocessor = recipe(formula = formula_all,
                                               data = data_2015
                                               ),
                         spec = rand_forest(
                              mode = "regression",
                              engine = "ranger",
                              mtry = tune(),
                              trees = tune(),
                              min_n = tune()
                            ))
tune_random_forest <- 
  workflow_random_forest %>%
  tune_grid(resamples = k_folds, 
            grid = expand_grid(mtry = c(5,13,20,21), trees = c(500), min_n = c(4)),
            metrics = metric_set(yardstick::rmse))

```
```{r}
tune_random_forest %>% collect_metrics() %>% select(-c(.config)) %>% filter(.metric=="rmse") %>% arrange(mean)
```
```{r}
tune_random_forest %>% 
  autoplot()
```
```{r}
tune_random_forest %>% select_by_one_std_err(metric = "rmse", mtry, desc(min_n))
```



## MARS
```{r}
workflow_all_mars <- 
  workflow(preprocessor = recipe(formula = formula_all,
                     data = data_2015
                     ),
           spec = mars(
                      mode = "regression",
                      engine = "earth",
                      num_terms = tune(),
                      prod_degree = tune(),
                      prune_method = tune()
                      )
  
)

tune_all_mars <- 
  workflow_all_mars %>% 
  tune_grid(resamples = k_folds, 
            grid = expand_grid(num_terms = c(7,8,11,12,13),prod_degree=c(1), prune_method=c("forward","none", "backward", "seqrep")),
            metrics = metric_set(yardstick::rmse))
```

```{r}
tune_all_mars %>% collect_metrics() %>% select(-c(.config)) %>% filter(.metric=="rmse") %>% filter(n==25) %>% arrange(mean)
```

```{r}
tune_all_mars %>% autoplot()
```
```{r}
tune_all_mars %>% select_by_one_std_err(metric = "rmse", num_terms, prod_degree)
```

```{r}
fit_mars_direct <- earth(formula_all, data = data_2015, degree = 1, nprune = 8, pmethod = "backward")

summary(fit_mars_direct)
```



## GAM
```{r}
gam_formula <- life_satisfaction ~ 
         undernourishment +
         obesity +

        
         drinking_water_basic +
         
         electricity +
         sanitation_basic +

         clean_cooking_gbd +
         s(air_pollution_particles) +
         s(air_pollution_ozone) +
         
         s(uhc_who) +
         s(dtp3) +


         unmet_contraception +
         
         social_support +
         
         s(stability) +
         
         cbn_poverty +
         unemployment_ilo +
         
         lower_secondary_school +

         s(voice) +

         freedom +



         s(alcohol) +

         HIV_unaids_untreated +

         s(gdp)

```

```{r}
gam_spec <- 
    gen_additive_mod(
      mode = "regression",
      select_features = TRUE,
      adjust_deg_free = tune(),
      engine = "mgcv"
)

gam_workflow <- 
  workflow() %>%
  add_recipe(recipe(formula = formula_all, data = data_2015)) %>% 
  add_model(gam_spec, formula = gam_formula)


gam_grid <- grid_regular(range_set(adjust_deg_free(), c(2.1,3.3)), levels = 7)

tune_results_gam <- gam_workflow %>% 
  tune_grid(resamples = k_folds, 
            grid = expand_grid(adjust_deg_free = c(2.1,2.9,2.92)), 
            metrics = metric_set(yardstick::rmse))

tune_results_gam %>% collect_metrics() %>% arrange(mean)

```
```{r}
tune_results_gam %>% autoplot()
```


```{r}
tune_results_gam %>% select_by_one_std_err(metric = "rmse", desc(adjust_deg_free))
```




# Selection
## Define and run tuned models

```{r}
selection_recipe_set <- 
   list("log_all" = recipe(formula = formula_all,
                     data = data_2015
                     ) %>%
                     step_log(gdp),
        "log_all" = recipe(formula = formula_all,
                     data = data_2015
                     ) %>%
                     step_log(gdp),
        "all" = recipe(formula = formula_all,
                     data = data_2015
                     ),
        "all" = recipe(formula = formula_all,
                     data = data_2015
                     ),
        "all" = recipe(formula = formula_all,
                     data = data_2015
                     )
  )

selection_models <- list(lasso = linear_reg(
                              penalty = 0.0355, 
                              mixture = 1, 
                              engine = "glmnet"),
                         ridge = linear_reg(
                                    penalty = 0.225, 
                                    mixture = 0) %>% 
                                  set_engine("glmnet", path_values = c(0, 10^seq(-4, 1, length.out = 11))),
                         forest = rand_forest(
                              mode = "regression",
                              engine = "ranger",
                              mtry = 5,
                              trees = 500,
                              min_n = 4
                            ),
                         mars = mars(
                              mode = "regression",
                              engine = "earth",
                              num_terms = 8,
                              prod_degree = 1,
                              prune_method = "backward"
                              ),
                         gam = gen_additive_mod(
                                    mode = "regression",
                                    select_features = TRUE,
                                    adjust_deg_free = 2.9,
                                    engine = "mgcv")
                         
)
      

selection_workflows <- 
  workflow_set(
    preproc = selection_recipe_set, 
    models = selection_models,
    cross=FALSE)

selection_workflows <- selection_workflows %>% update_workflow_model("all_gam", 
                                                                     gen_additive_mod(
                                                                       mode = "regression",
                                                                       select_features = TRUE,
                                                                       adjust_deg_free = 2.9,
                                                                       engine = "mgcv"), 
                                                                     formula = gam_formula)
```

```{r}
cv_results_ls_k_selection <- selection_workflows %>% workflow_map("fit_resamples", resamples = k_folds, verbose = TRUE)
```
add the results of OLS for comparison:
```{r}
cv_results_ls_k_selection <- cv_results_ls_k_selection %>% rbind(cv_results_ls_k_scan %>% filter(wflow_id=="log_all_ols")) 
```

... and the results of GDP only:
```{r}
cv_results_ls_k_gdp <- 
  workflow_set(preproc = list(log_GDP = recipe(formula = life_satisfaction~gdp, data = data_2015) %>% step_log(gdp)),
            model = list(ols = lin_spec)) %>% 
  workflow_map("fit_resamples", resamples = k_folds, verbose = TRUE)

cv_results_ls_k_selection <- cv_results_ls_k_selection %>% rbind(cv_results_ls_k_gdp %>% filter(wflow_id=="log_GDP_ols")) 
```



```{r}
saveRDS(cv_results_ls_k_selection, file = "../results/cv_results_ls_k_selection.rds", ascii = FALSE, version = NULL,
        compress = TRUE, refhook = NULL)

```



## Generate statistics
```{r}
cv_results_ls_k_selection <- readRDS(file = "../results/cv_results_ls_k_selection.rds")
```

```{r}
cv_results_ls_k_selection <- cv_results_ls_k_selection %>% mutate(wflow_id = str_replace(wflow_id, "linear", "ols"))
```



```{r}
selected_workflows_statistics <- 
  rank_results(cv_results_ls_k_selection, rank_metric = "rmse") %>% 
  filter(.metric == "rmse") %>% 
  transmute(workflow_id=wflow_id, rmse=mean, rmse_std_err=std_err) %>%
  rowwise() %>% 
  mutate(moran_neighbors = cv_results_ls_k_selection %>%
                                    extract_workflow(workflow_id) %>% 
                                    workflow_residual_moran_neighbors(data_2015, 
                                                                      country_neighbors, 
                                                                      name_true_values = "life_satisfaction" ) %>% 
                                    pull(moran_index)
                                  
         ) %>% 
  mutate(complexity = ifelse(
                          str_detect(workflow_id, ".lasso" ) ||  str_detect(workflow_id, ".ridge" ),
                                           cv_results_ls_k_selection %>%
                                           extract_workflow(workflow_id) %>%
                                           fit(data=data_2015) %>%
                                           tidy() %>% 
                                           filter(estimate!=0) %>% 
                                           nrow(),
                          ifelse(str_detect(workflow_id, ".gam"),
                                           cv_results_ls_k_selection %>%
                                            extract_workflow("all_gam") %>%
                                            fit(data=data_2015) %>% 
                                            extract_fit_engine() %>% 
                                            summary() %>% 
                                            with(length(p.coeff) + sum(edf)) %>% 
                                            round(2), 
                             cv_results_ls_k_selection %>% 
                               extract_workflow(workflow_id) %>% 
                               fit(data=data_2015) %>% 
                               extract_fit_engine() %>% 
                               coefficients() %>% 
                               length()
                             ))
         ) %>% 
  mutate(complexity = ifelse(str_detect(workflow_id, ".mars*" ),8, complexity)) # manually change mars due to interaction terms


saveRDS(selected_workflows_statistics, file = "../results/selected_workflows_statistics_ls.rds", ascii = FALSE, version = NULL,
        compress = TRUE, refhook = NULL)

```



## Pretty summary table
```{r}
selected_workflows_statistics <- readRDS(file = "../results/selected_workflows_statistics_ls.rds") %>% print()
```

```{r}
pretty_table <- 
  selected_workflows_statistics %>% 
  rename(Model = "workflow_id", `Cross-validation error` = "rmse", 
         `Standard deviation`= "rmse_std_err", `Moran's I` = "moran_neighbors", Complexity = "complexity") %>% 
  select(-Complexity) %>% 
  mutate(Model = case_when(Model == "log_all_ols" ~ "OLS all predictors",
                           Model == "log_GDP_ols" ~ "OLS GDP only",
                           Model == "all_gam" ~ "GAM",
                           Model == "log_all_ridge" ~ "Ridge",
                           Model == "log_all_lasso" ~ "LASSO",
                           Model == "all_mars" ~ "MARS",
                           Model == "all_forest" ~ "Random Forest",
                           TRUE ~ Model)) %>% 
  arrange(factor(Model, levels = c("OLS GDP only", "OLS all predictors", "LASSO", "Ridge", "MARS", "GAM", "Random forest")))

pretty_table %>% 
  column_to_rownames(var = 'Model') %>% 
  stargazer(summary=FALSE,  
            align=TRUE, 
            title = "Cross-validation errors of the tuned models for life satisfaction, hyperparameters selected with one-standard-error rule. The values of the ordinary least squares models using GDP only or all predictors are shown for comparison.",
            label = "tab:cv_models_ls")
```


make a plot showing the differences in performance:
```{r}
pretty_table %>% 
  mutate(Model = factor(Model, levels=Model)) %>%  # to lock the ordering for ggplot
  ggplot() +
  geom_col(aes(x=`Cross-validation error`, y=fct_rev(Model)), width=0.4) +
  theme_light() +
  theme(text = element_text(size=12, family="LM Roman 10")) +
  geom_hline(yintercept = 5.5) +
  labs(y = NULL, x = "Cross-validation error (0-10 Cantril Scale)")
ggsave(file = "../results/figures/model_selection_cv_error_life_satisfaction.pdf", dpi = 600, width = 160, height = 72.7272, units = "mm",device = cairo_pdf)
```




## Details of final models


### GAM

```{r}
fit_gam_direct <- gam(gam_formula, data = data_2015, select = TRUE, gamma = 2.9)
summary(fit_gam_direct)
```

```{r}
draw(fit_gam_direct, shade = TRUE)
```
```{r}
sm <- smooth_estimates(fit_gam_direct)
```


```{r}
sm %>%
  add_confint() %>%
  ggplot(aes(y = est, x = uhc_who)) +
    geom_ribbon(aes(ymin = lower_ci, ymax = upper_ci),
                alpha = 0.2) +
    geom_line() +
    labs(y = "Partial effect (years)",
         x = "UHC index") +
  theme_light() &
  theme(text = element_text(size=10, family="LM Roman 10"))
ggsave(file = "../results/figures/gam_ls_uhc.pdf", dpi = 600, width = 78.4, height = 58.8, units = "mm",device = cairo_pdf)
```


```{r}
sm %>%
  add_confint() %>%
  ggplot(aes(y = est, x = gdp)) +
    geom_ribbon(aes(ymin = lower_ci, ymax = upper_ci),
                alpha = 0.2) +
    geom_line() +
    labs(y = "Partial effect (years)",
         x = "GDP ($ per capita)") +
  theme_light() &
  theme(text = element_text(size=10, family="LM Roman 10"))
ggsave(file = "../results/figures/gam_ls_gdp.pdf", dpi = 600, width = 78.4, height = 58.8, units = "mm",device = cairo_pdf)
```

```{r}
appraise(fit_gam_direct)
```


### Random Forest
 
get variable importances
```{r}
fit_forest_direct <- ranger(formula = formula_all, 
                            data = data_2015, 
                            num.trees = 500,
                            mtry = 5,
                            min.node.size = 4,
                            importance = "permutation",
                            scale.permutation.importance = TRUE
                            )
forest_importance <- 
  fit_forest_direct$variable.importance %>% 
  as.list() %>% 
  as.data.frame() %>% 
  rename(Undernourishment = "undernourishment",
         Obesity = "obesity",
         `Drinking water` = "drinking_water_basic", 
         Electricity = "electricity",
         Sanitation = "sanitation_basic",
         `Clean cooking` = "clean_cooking_gbd", 
         `Air pollution (particles)` = "air_pollution_particles",
         `Air pollution (ozone)` = "air_pollution_ozone",
         UHC = "uhc_who", 
         DTP3 = "dtp3",
         `Unmet contraception` = "unmet_contraception",
         `Social support` = "social_support",
         Stability = "stability",
         `CBN poverty` = cbn_poverty,   
         Unemployment = "unemployment_ilo", 
         `Lower secondary school`= "lower_secondary_school", 
         Voice = "voice",
         Freedom = "freedom",
         Alcohol = "alcohol",
         `HIV (untreated)` = "HIV_unaids_untreated", 
         GDP = "gdp"
         ) %>% 
  pivot_longer(everything(), names_to = "Predictor", values_to = "Importance")
```

```{r}
forest_importance %>% 
  mutate(Predictor = factor(Predictor, levels=Predictor)) %>%  # to lock the ordering for ggplot
  ggplot() + 
  geom_col(aes(x = Importance, y = fct_rev(Predictor)), width = 0.4) +
  theme_light() +
  theme(text = element_text(size=12, family="LM Roman 10")) +
  #theme(axis.text.x = element_text(angle = 90, hjust = 0.5, vjust = 0.5)) + # to rotate the labels
  labs(y = NULL)

ggsave(file = "../results/figures/random_forest_variable_importance.pdf", dpi = 600, width = 160, height = 200, units = "mm",device = cairo_pdf)
  
```


### Lasso

model with standardized data
```{r}
recipe_normalize <- recipe(formula = formula_all, data = data_2015) %>% 
                    step_log(gdp) %>% 
                    step_normalize(all_predictors())


log_all_lasso_0.0355_standard <- 
  workflow(preprocessor = recipe_normalize,
           spec = linear_reg(penalty = 0.0355,
                             mixture = 1) %>% 
             set_engine("glmnet", standardize = FALSE, thresh=1e-30))

fit_log_all_lasso_0.0355_standard <- 
  log_all_lasso_0.0355_standard %>% 
  fit(data_2015)

tidy(fit_log_all_lasso_0.0355_standard)    
```

```{r}
fit_log_all_lasso_0.0355 <- 
  cv_results_ls_k_selection %>% 
  extract_workflow("log_all_lasso_0.0355") %>%
  fit(data_2015) 

fit_log_all_lasso_0.0355 %>% tidy() %>% select(term, model_1=estimate) %>% filter(model_1 != 0)
```



```{r}
compare_lasso_le_ls <- cv_results_le_k_selection %>% extract_workflow("all_lasso_0.36") %>%
      fit(data_2015) %>% tidy() %>% select(term, `life expectancy`=estimate) %>% rowwise() %>% mutate(`life expectancy` = ifelse(`life expectancy` == 0, NA, `life expectancy`)) %>% 
  full_join(
    cv_results_ls_k_selection %>% extract_workflow("log_all_lasso_0.0355") %>%
      fit(data_2015) %>% tidy() %>% select(term, `life satisfaction`=estimate) %>% rowwise() %>% mutate(`life satisfaction` = ifelse(`life satisfaction` == 0, NA, `life satisfaction`))
  ) %>% 
 mutate(term = recode(term, "clean_cooking_gbd" = "clean cooking", 
         "drinking_water_basic" = "drinking water", 
         "unemployment_ilo" = "unemployment", 
         "sanitation_basic" = "sanitation", 
         "uhc_who" = "UHC", 
         "HIV_unaids_untreated" = "HIV (untreated)", 
         "gdp" = "GDP", 
         "cbn_poverty" = "CBN poverty",                           
         "air_pollution_ozone" = "air pollution (ozone)", 
         "air_pollution_particles" = "air pollution (particles)", 
         "dtp3" = "DTP3", 
         "social_support" = "social support", 
         "unmet_contraception" = "unmet contraception", 
         "lower_secondary_school" = "lower secondary school")) %>% 
  mutate(across(where(is.numeric), round, 3))


stargazer(compare_lasso_le_ls, summary = F, rownames = F, digits = 2, digits.extra=5, align = T)

```


#### post-selection inference

```{r}
predictors <- tidy(fit_log_all_lasso_0.0355) %>% filter(term!= "(Intercept)") %>% pull(term)
predictors_selected <- tidy(fit_log_all_lasso_0.0355) %>% filter(estimate!=0, term!= "(Intercept)") %>% pull(term)
x <- as.matrix(data_2015 %>% 
                 select(all_of(predictors)) %>% 
                 mutate(gdp = log(gdp)) %>% 
                 mutate(across(where(is.numeric),  ~(scale(.) %>% as.vector)))
               )
y <- data_2015 %>% pull(life_satisfaction)

gfit <- glmnet(x,y,standardize=FALSE)

n=data_2015 %>% summarise(n=n()) %>% pull(n)

lambda= 0.0355*n

beta <- coef(gfit, x=x, y=y, s=lambda/n, exact=TRUE)[-1]
  #tidy(fit_log_all_lasso_0.0355_standard) %>% filter(term!="(Intercept)") %>% pull(estimate)

postInf <- fixedLassoInf(x,y,beta,lambda, alpha = 0.05)

p_post <- postInf$pv %>% setNames(predictors_selected)
```
```{r}
postInf
```
```{r}
lm_sel_standard <- lm(life_satisfaction ~ 
             obesity +
             clean_cooking_gbd +
             uhc_who +
             dtp3 +
             social_support +
             unemployment_ilo +
             voice +
             freedom +
             alcohol +
             HIV_unaids_untreated + 
             gdp, data_2015 %>% 
               mutate(gdp=log(gdp)) %>% 
               mutate(across(where(is.numeric) & !population & !life_satisfaction,  ~(scale(.) %>% as.vector))))
summary(lm_sel_standard)
```
```{r}
lm_sel <- lm(life_satisfaction ~ 
             obesity +
             clean_cooking_gbd +
             uhc_who +
             dtp3 +
             social_support +
             unemployment_ilo +
             voice +
             freedom +
             alcohol +
             HIV_unaids_untreated + 
             gdp, data_2015 %>% 
               mutate(gdp=log(gdp)))# %>% 
               #mutate(across(where(is.numeric) & !population & !life_satisfaction,  ~(scale(.) %>% as.vector))))
summary(lm_sel)
```

make summary table with stargazer but use p values from post-selection inference
```{r}
stargazer(lm_sel, lm_sel_standard,
          report = 'vc*', 
          title = "Results of post-selection inference for best lasso model, for predictors in original units (1) and standardised (2)", 
          #dep.var.caption = "Life satisfaction (0-10 Cantril Scale)", 
          dep.var.labels = "Life satisfaction (0-10 Cantril Scale)", 
          #column.labels=c("original units", "standardised predictors"), 
          covariate.labels = c("Intercept", "Obesity", "Clean cooking", "UHC", "DTP3", "Social support", "Unemployment", "Voice", "Freedom", "Alcohol", "HIV (untreated)", "log(GDP)"),
          intercept.bottom = FALSE,
          align = TRUE, 
          omit.stat=c("LL","f"),
          omit = c("Constant"),
          p = list(p_post, p_post),
          star.cutoffs =c(0.05, 0.01, 0.001), 
          #notes = "Standard errors are shown in parentheses.", 
          notes.append = T, 
          model.numbers=T, 
          no.space=T,
          label= "tab:post_sel_ls"
          )
```





#### debiased lasso

use fixedLassoInf with type "full", according to the documentation this gives you the debiased lasso

```{r}
debiasedLasso <- fixedLassoInf(x,y,beta,lambda, alpha = 0.05, type = "full")
debiasedLasso
```

Why are only the coefficients of the lasso selection shown? The values coincide with the OLS fit

```{r}
lm(formula_all, data_2015 %>% mutate(gdp=log(gdp)) %>% mutate(across(where(is.numeric) & !population & !life_satisfaction,  ~(scale(.) %>% as.vector)))) %>% summary()
```





#### test set performance

As test set, use the countries that had not full data coverage for all predictors but for those selected by the lasso model

```{r}
data_2015_imputed <- read_excel("../data/dataset_need_satisfiers_2015_imputed.xlsx")
```
```{r}
predictors_selected <- tidy(fit_log_all_lasso_0.0355) %>% filter(estimate!=0, term!= "(Intercept)") %>% pull(term)
countries_used <- data_2015 %>% pull(country_name)
```



```{r}
test_set <- data_2015_imputed %>% filter(!country_name %in% countries_used) %>% drop_na(country_name, country_code, continent, region, population, life_satisfaction, all_of(predictors_selected))
```



```{r}
rmse_vec(test_set[["life_satisfaction"]],(fit_log_all_lasso_0.0355 %>% predict(test_set))$.pred)
```
compare to the test set performance of log(GDP)
```{r}
rmse_vec(test_set[["life_satisfaction"]],(lm(life_satisfaction ~ log(gdp), data_2015) %>% predict(test_set)))

```
Our model performs much better :)



